{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 03: 실시간 음성 에이전트 (Realtime Voice Agent)\n",
        "\n",
        "이 노트북에서는 실시간 음성 스트리밍 기반 에이전트 서버를 구성합니다. 이번 실습은 웹소켓을 사용해야 하므로 노트북에서는 실행되지 않습니다. \n",
        "[ch03](ch03)의 코드를 사용하세요.\n",
        "\n",
        "## 주요 내용\n",
        "- Realtime API 연결\n",
        "- 웹소켓 브리지 구성\n",
        "- 음성 스트리밍 처리\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/TeeDDub/Building-Applications-with-AI-Agents/blob/main/notebook/ch03_realtime_voice_agent.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 패키지 설치\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -q fastapi uvicorn websockets python-dotenv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. API 키 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "    print(\"✅ Colab Secrets에서 API 키를 불러왔습니다.\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = \"sk-your-api-key-here\"\n",
        "    print(\"⚠️ API 키를 직접 입력해주세요.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. realtime_voice_agent.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이 코드는 WebSocket 서버를 실행합니다. Colab에서 직접 실행하기 어려우므로 원본 파일을 참고해 로컬 환경에서 실행하세요.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Realtime API와 WebSocket 브리지로 음성 스트리밍 서버를 구성합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# realtime_voice_agent.py\n",
        "import os, json, base64, asyncio, websockets\n",
        "from fastapi import FastAPI, WebSocket\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# 환경변수 확인\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()\n",
        "except ImportError:\n",
        "    pass  \n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not OPENAI_API_KEY:\n",
        "    raise ValueError(\n",
        "        \"OPENAI_API_KEY가 설정되지 않았습니다. \"\n",
        "        \"환경변수 또는 .env 파일에서 설정해주세요.\"\n",
        "    )\n",
        "\n",
        "VOICE          = \"Coral\"                 # 목소리 선택\n",
        "PCM_SR         = 24000                   # 클라이언트 사이드에서 사용할 샘플레이트(16kHz)\n",
        "PORT           = 5050\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.websocket(\"/voice\")\n",
        "async def voice_bridge(ws: WebSocket) -> None:\n",
        "    \"\"\"\n",
        "    1. 브라우저가 ws://host:5050/voice로 WebSocket 연결\n",
        "    2. OpenAI Realtime API (wss://api.openai.com/v1/realtime)에 연결 및 세션 초기화\n",
        "    3. from_client(): 브라우저 → OpenAI로 PCM16 오디오 스트리밍 (input_audio_buffer.append)\n",
        "    4. to_client(): OpenAI → 브라우저로 어시스턴트 음성 델타 전달 (response.audio.delta)\n",
        "    5. 인터럽션 처리: 사용자 발화 감지 시 어시스턴트 응답 즉시 중단 (conversation.item.truncate)\n",
        "    \"\"\"\n",
        "    await ws.accept()\n",
        "\n",
        "    # OpenAI Realtime API에 하위 연결 생성\n",
        "    openai_ws = await websockets.connect(\n",
        "        \"wss://api.openai.com/v1/realtime?model=gpt-realtime-mini\",\n",
        "        additional_headers={\n",
        "            \"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
        "            \"OpenAI-Beta\" : \"realtime=v1\"\n",
        "        },\n",
        "        max_size=None, max_queue=None # 데모 단순화를 위해 무제한 설정\n",
        "    )\n",
        "\n",
        "    # Realtime 세션 초기화\n",
        "    await openai_ws.send(json.dumps({\n",
        "        \"type\": \"session.update\",\n",
        "        \"session\": {\n",
        "            \"turn_detection\": {\"type\": \"server_vad\"},\n",
        "            \"input_audio_format\": f\"pcm16\",\n",
        "            \"output_audio_format\": f\"pcm16\",\n",
        "            \"voice\": VOICE,\n",
        "            \"modalities\": [\"audio\"],\n",
        "            \"instructions\": \"당신은 간결한 AI 에이전트입니다. 한국어로 대답하세요. 최대한 예의 있는 말투로 대답하세요. 최대한 짧게 대답하세요.\"\n",
        "        }\n",
        "    }))\n",
        "\n",
        "    last_assistant_item = None          # 현재 어시스턴트 응답 추적\n",
        "    latest_pcm_ts       = 0             # 클라이언트로부터의 ms 타임스탬프\n",
        "    pending_marks       = []\n",
        "\n",
        "    async def from_client() -> None:\n",
        "        \"\"\"브라우저에서 OpenAI로 마이크 PCM 청크를 중계\"\"\"\n",
        "        nonlocal latest_pcm_ts\n",
        "        async for msg in ws.iter_text():\n",
        "            data = json.loads(msg)\n",
        "            pcm = base64.b64decode(data[\"audio\"])\n",
        "            latest_pcm_ts += int(len(pcm) / (PCM_SR * 2) * 1000)  # 단순 ms 카운터\n",
        "            await openai_ws.send(json.dumps({\n",
        "                \"type\": \"input_audio_buffer.append\",\n",
        "                \"audio\": base64.b64encode(pcm).decode(\"ascii\")\n",
        "            }))\n",
        "\n",
        "    async def to_client() -> None:\n",
        "        \"\"\"어시스턴트 오디오 중계 및 인터럽션 처리\"\"\"\n",
        "        nonlocal last_assistant_item, pending_marks\n",
        "        async for raw in openai_ws:\n",
        "            msg = json.loads(raw)\n",
        "\n",
        "            # 어시스턴트가 말하는 경우\n",
        "            if msg[\"type\"] == \"response.audio.delta\":\n",
        "                pcm = base64.b64decode(msg[\"delta\"])\n",
        "                await ws.send_json({\"audio\": base64.b64encode(pcm).decode(\"ascii\")})\n",
        "                last_assistant_item = msg.get(\"item_id\")\n",
        "\n",
        "            # 사용자가 말하기 시작 → 어시스턴트 발화 중단\n",
        "            if msg[\"type\"] == \"input_audio_buffer.speech_started\" and last_assistant_item:\n",
        "                await openai_ws.send(json.dumps({\n",
        "                    \"type\": \"conversation.item.truncate\",\n",
        "                    \"item_id\": last_assistant_item,\n",
        "                    \"content_index\": 0,\n",
        "                    \"audio_end_ms\": 0   # 즉시 중단\n",
        "                }))\n",
        "                last_assistant_item = None\n",
        "                pending_marks.clear()\n",
        "\n",
        "    try:\n",
        "        await asyncio.gather(from_client(), to_client())\n",
        "    finally:\n",
        "        await openai_ws.close()\n",
        "        await ws.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import uvicorn\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"\\n실시간 음성 에이전트 서버가 시작됩니다...\")\n",
        "    print(f\"\\n서버가 실행되면 브라우저에서 index.html 파일을 열어주세요!\")\n",
        "    print(f\"\\n파일 위치: ch03/index.html\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "    uvicorn.run(\"realtime_voice_agent:app\", host=\"0.0.0.0\", port=PORT)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "building-applications-with-ai-agents",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}