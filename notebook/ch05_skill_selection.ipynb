{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 05: ìŠ¤í‚¬ ì„ íƒ (Skill Selection)\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” LangGraphë¥¼ ì‚¬ìš©í•œ ì¡°ê±´ë¶€ ë¼ìš°íŒ…ê³¼ ìŠ¤í‚¬ ì„ íƒì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "\n",
        "## ì£¼ìš” ë‚´ìš©\n",
        "- LangGraph ì¡°ê±´ë¶€ ì—£ì§€\n",
        "- ë¬¸ì œ ë¶„ë¥˜ ë° ë¼ìš°íŒ…\n",
        "- ê³„ì¸µì  ì›Œí¬í”Œë¡œìš°\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-repo/notebook/ch05_skill_selection.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain-openai langgraph python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "except:\n",
        "    pass\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = \"sk-your-api-key-here\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LangGraph ì¡°ê±´ë¶€ ë¼ìš°íŒ… ì˜ˆì œ\n",
        "\n",
        "ê³ ê° ì§€ì› ìš”ì²­ì„ billing ë˜ëŠ” technicalë¡œ ë¶„ë¥˜í•˜ê³  ì ì ˆí•œ í•¸ë“¤ëŸ¬ë¡œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import TypedDict, Optional\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# LLM ì´ˆê¸°í™”\n",
        "llm = init_chat_model(model=\"gpt-5-mini\")\n",
        "\n",
        "# State ì •ì˜\n",
        "class AgentState(TypedDict):\n",
        "    user_message: str\n",
        "    user_id: str\n",
        "    issue_type: Optional[str]\n",
        "    step_result: Optional[str]\n",
        "    response: Optional[str]\n",
        "\n",
        "print(\"âœ… State ë° LLM ì„¤ì • ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë…¸ë“œ ì •ì˜\n",
        "def categorize_issue(state: AgentState) -> AgentState:\n",
        "    \"\"\"ë¬¸ì œë¥¼ billing ë˜ëŠ” technicalë¡œ ë¶„ë¥˜\"\"\"\n",
        "    prompt = f\"ì´ ì§€ì› ìš”ì²­ì„ 'billing' ë˜ëŠ” 'technical'ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.\\n\\në©”ì‹œì§€: {state['user_message']}\"\n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    kind = response.content.strip().lower()\n",
        "    if \"billing\" in kind:\n",
        "        kind = \"billing\"\n",
        "    else:\n",
        "        kind = \"technical\"\n",
        "    return {\"issue_type\": kind}\n",
        "\n",
        "def handle_invoice(state: AgentState) -> AgentState:\n",
        "    return {\"step_result\": f\"Invoice details for {state['user_id']}\"}\n",
        "\n",
        "def handle_refund(state: AgentState) -> AgentState:\n",
        "    return {\"step_result\": \"Refund process initiated\"}\n",
        "\n",
        "def handle_login(state: AgentState) -> AgentState:\n",
        "    return {\"step_result\": \"Password reset link sent\"}\n",
        "\n",
        "def summarize_response(state: AgentState) -> AgentState:\n",
        "    details = state.get(\"step_result\", \"\")\n",
        "    prompt = f\"ë‹¤ìŒ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê°„ê²°í•œ ê³ ê° ì‘ë‹µì„ ì‘ì„±í•˜ì„¸ìš”: {details}\"\n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    return {\"response\": response.content.strip()}\n",
        "\n",
        "print(\"âœ… ë…¸ë“œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê·¸ë˜í”„ êµ¬ì„±\n",
        "graph_builder = StateGraph(AgentState)\n",
        "\n",
        "# ë…¸ë“œ ì¶”ê°€\n",
        "graph_builder.add_node(\"categorize_issue\", categorize_issue)\n",
        "graph_builder.add_node(\"handle_invoice\", handle_invoice)\n",
        "graph_builder.add_node(\"handle_refund\", handle_refund)\n",
        "graph_builder.add_node(\"handle_login\", handle_login)\n",
        "graph_builder.add_node(\"summarize_response\", summarize_response)\n",
        "\n",
        "# ì—£ì§€ ì¶”ê°€\n",
        "graph_builder.add_edge(START, \"categorize_issue\")\n",
        "\n",
        "# ì¡°ê±´ë¶€ ë¼ìš°íŒ…\n",
        "def top_router(state: AgentState):\n",
        "    return \"billing\" if state[\"issue_type\"] == \"billing\" else \"technical\"\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"categorize_issue\",\n",
        "    top_router,\n",
        "    {\"billing\": \"handle_invoice\", \"technical\": \"handle_login\"}\n",
        ")\n",
        "\n",
        "# í›„ì† ì²˜ë¦¬\n",
        "graph_builder.add_edge(\"handle_invoice\", \"summarize_response\")\n",
        "graph_builder.add_edge(\"handle_login\", \"summarize_response\")\n",
        "\n",
        "# ì»´íŒŒì¼\n",
        "graph = graph_builder.compile()\n",
        "print(\"âœ… ê·¸ë˜í”„ ì»´íŒŒì¼ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
        "initial_state = {\n",
        "    \"user_message\": \"ì•ˆë…•í•˜ì„¸ìš”, ì¸ë³´ì´ìŠ¤ ê´€ë ¨ ë„ì›€ì„ ë°›ê³  ì‹¶ìŠµë‹ˆë‹¤.\",\n",
        "    \"user_id\": \"U1234\"\n",
        "}\n",
        "\n",
        "result = graph.invoke(initial_state)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(f\"ğŸ·ï¸ ë¶„ë¥˜ëœ ë¬¸ì œ ìœ í˜•: {result['issue_type']}\")\n",
        "print(f\"ğŸ“ ì²˜ë¦¬ ê²°ê³¼: {result['step_result']}\")\n",
        "print(f\"ğŸ¤– ìµœì¢… ì‘ë‹µ: {result['response']}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
