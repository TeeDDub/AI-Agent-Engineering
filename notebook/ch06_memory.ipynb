{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 06: 메모리 (Memory)\n",
        "\n",
        "이 노트북에서는 에이전트의 단기/장기 메모리 구현을 학습합니다.\n",
        "\n",
        "## 주요 내용\n",
        "- 단기 메모리 (Short-term Memory)\n",
        "- 시맨틱 메모리와 벡터 검색\n",
        "- LangGraph 체크포인터\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-repo/notebook/ch06_memory.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain-openai langgraph python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "except:\n",
        "    pass\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = \"sk-your-api-key-here\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 메모리 없는 대화 (문제 상황)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "from langgraph.graph import StateGraph, MessagesState, START\n",
        "\n",
        "# LLM 초기화\n",
        "llm = init_chat_model(model=\"gpt-5-mini\", temperature=0)\n",
        "\n",
        "def call_model(state: MessagesState):\n",
        "    response = llm.invoke(state[\"messages\"])\n",
        "    return {\"messages\": response}\n",
        "\n",
        "# 메모리 없는 그래프 구성\n",
        "builder = StateGraph(MessagesState)\n",
        "builder.add_node(\"call_model\", call_model)\n",
        "builder.add_edge(START, \"call_model\")\n",
        "graph_no_memory = builder.compile()\n",
        "\n",
        "print(\"⚠️ 메모리 없는 그래프 생성\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 메모리 없이 대화 테스트\n",
        "print(\"첫 번째 메시지:\")\n",
        "input1 = {\"type\": \"user\", \"content\": \"안녕하세요! 제 이름은 민혁입니다.\"}\n",
        "for chunk in graph_no_memory.stream({\"messages\": [input1]}, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()\n",
        "\n",
        "print(\"\\n두 번째 메시지 (이전 대화 기억 못함):\")\n",
        "input2 = {\"type\": \"user\", \"content\": \"제 이름이 뭐라고 했죠?\"}\n",
        "for chunk in graph_no_memory.stream({\"messages\": [input2]}, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 메모리 있는 대화 (해결책)\n",
        "\n",
        "LangGraph의 `MemorySaver`를 사용하여 대화 상태를 유지합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "# 메모리 체크포인터 설정\n",
        "memory = MemorySaver()\n",
        "graph_with_memory = builder.compile(checkpointer=memory)\n",
        "\n",
        "print(\"✅ 메모리가 있는 그래프 생성\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 메모리와 함께 대화 테스트\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}  # 세션 ID\n",
        "\n",
        "print(\"첫 번째 메시지:\")\n",
        "input1 = {\"type\": \"user\", \"content\": \"안녕하세요! 제 이름은 민혁입니다.\"}\n",
        "for chunk in graph_with_memory.stream({\"messages\": [input1]}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()\n",
        "\n",
        "print(\"\\n두 번째 메시지 (이전 대화 기억함!):\")\n",
        "input2 = {\"type\": \"user\", \"content\": \"제 이름이 뭐라고 했죠?\"}\n",
        "for chunk in graph_with_memory.stream({\"messages\": [input2]}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
