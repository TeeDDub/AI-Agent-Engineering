{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 08: ê³µê¸‰ë§ ë¬¼ë¥˜ ì—ì´ì „íŠ¸\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ê³µê¸‰ë§ ë° ë¬¼ë¥˜ ê´€ë¦¬ë¥¼ ìœ„í•œ AI ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.\n",
        "\n",
        "## ì£¼ìš” ë‚´ìš©\n",
        "- ë‹¤ì–‘í•œ ë¬¼ë¥˜ ë„êµ¬ ì •ì˜\n",
        "- ë³µì¡í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ê³„\n",
        "- ë„êµ¬ í˜¸ì¶œ ë° ê²°ê³¼ ì²˜ë¦¬\n",
        "\n",
        "âš ï¸ **ì°¸ê³ **: ì›ë³¸ ì½”ë“œì˜ Traceloop/Loki ê´€ì¸¡ì„± ê¸°ëŠ¥ì€ Colab í˜¸í™˜ì„ ìœ„í•´ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-repo/notebook/ch08_supply_chain_agent.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain-openai langgraph python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "except:\n",
        "    pass\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = \"sk-your-api-key-here\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ë¬¼ë¥˜ ë„êµ¬ ì •ì˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import operator\n",
        "from typing import Annotated, Sequence, TypedDict, Optional\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage\n",
        "from langchain_core.messages.tool import ToolMessage\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.graph import StateGraph\n",
        "\n",
        "# Loki ëŒ€ì²´ í•¨ìˆ˜ (Colabìš©)\n",
        "def log_to_loki(label, message):\n",
        "    print(f\"[LOG] {label}: {message}\")\n",
        "\n",
        "@tool\n",
        "def manage_inventory(sku: Optional[str] = None, **kwargs) -> str:\n",
        "    \"\"\"ì¬ê³  ìˆ˜ì¤€, ì¬ê³  ë³´ì¶©, ê°ì‚¬ ë° ìµœì í™” ì „ëµì„ ê´€ë¦¬í•©ë‹ˆë‹¤.\"\"\"\n",
        "    print(f\"[ë„êµ¬] manage_inventory(sku={sku})\")\n",
        "    return \"inventory_management_initiated\"\n",
        "\n",
        "@tool\n",
        "def track_shipments(origin: Optional[str] = None, **kwargs) -> str:\n",
        "    \"\"\"ë°°ì†¡ ìƒíƒœ, ì§€ì—° ì‚¬í•­ì„ ì¶”ì í•˜ê³  ë°°ì†¡ ë¬¼ë¥˜ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤.\"\"\"\n",
        "    print(f\"[ë„êµ¬] track_shipments(origin={origin})\")\n",
        "    return \"shipment_tracking_updated\"\n",
        "\n",
        "@tool\n",
        "def forecast_demand(season: Optional[str] = None, **kwargs) -> str:\n",
        "    \"\"\"ìˆ˜ìš” íŒ¨í„´, ê³„ì ˆì  ì¶”ì„¸ë¥¼ ë¶„ì„í•˜ê³  ì˜ˆì¸¡ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
        "    print(f\"[ë„êµ¬] forecast_demand(season={season})\")\n",
        "    return \"demand_forecast_generated\"\n",
        "\n",
        "@tool\n",
        "def send_logistics_response(operation_id: Optional[str] = None, message: Optional[str] = None) -> str:\n",
        "    \"\"\"ì´í•´ê´€ê³„ìì—ê²Œ ë¬¼ë¥˜ ì—…ë°ì´íŠ¸ ë˜ëŠ” ê¶Œì¥ ì‚¬í•­ì„ ì „ì†¡í•©ë‹ˆë‹¤.\"\"\"\n",
        "    print(f\"[ë„êµ¬] send_logistics_response â†’ {message}\")\n",
        "    return \"logistics_response_sent\"\n",
        "\n",
        "TOOLS = [manage_inventory, track_shipments, forecast_demand, send_logistics_response]\n",
        "print(\"âœ… ë¬¼ë¥˜ ë„êµ¬ ì •ì˜ ì™„ë£Œ:\", [t.name for t in TOOLS])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ê³µê¸‰ë§ ì—ì´ì „íŠ¸ êµ¬ì¶•\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LLM ì´ˆê¸°í™” ë° ë„êµ¬ ë°”ì¸ë”©\n",
        "llm = init_chat_model(model=\"gpt-5-mini\", verbose=True).bind_tools(TOOLS)\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    operation: Optional[dict]\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "\n",
        "def call_model(state: AgentState):\n",
        "    history = state[\"messages\"]\n",
        "    operation = state.get(\"operation\", {})\n",
        "    if not operation:\n",
        "        operation = {\"operation_id\": \"UNKNOWN\", \"type\": \"general\"}\n",
        "    \n",
        "    operation_json = json.dumps(operation, ensure_ascii=False)\n",
        "    system_prompt = f\"\"\"ë‹¹ì‹ ì€ ìˆ™ë ¨ëœ ê³µê¸‰ë§ ë° ë¬¼ë¥˜ ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì „ë¬¸ ë¶„ì•¼:\n",
        "- ì¬ê³  ê´€ë¦¬ ë° ìˆ˜ìš” ì˜ˆì¸¡\n",
        "- ìš´ì†¡ ë° ë°°ì†¡ ìµœì í™”\n",
        "- í’ˆì§ˆ ê´€ë¦¬ ë° ë¹„ìš© ìµœì í™”\n",
        "\n",
        "ê³µê¸‰ë§ ìš´ì˜ì„ ê´€ë¦¬í•  ë•Œ:\n",
        "1) ë¬¼ë¥˜ ê³¼ì œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤\n",
        "2) ì ì ˆí•œ ê³µê¸‰ë§ ê´€ë¦¬ ë„êµ¬ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤\n",
        "3) send_logistics_responseë¡œ ê¶Œì¥ ì‚¬í•­ì„ ì œê³µí•©ë‹ˆë‹¤\n",
        "\n",
        "ì‘ì—…: {operation_json}\"\"\"\n",
        "\n",
        "    full = [SystemMessage(content=system_prompt)] + history\n",
        "    first = llm.invoke(full)\n",
        "    messages = [first]\n",
        "\n",
        "    if getattr(first, \"tool_calls\", None):\n",
        "        for tc in first.tool_calls:\n",
        "            fn = next(t for t in TOOLS if t.name == tc['name'])\n",
        "            out = fn.invoke(tc[\"args\"])\n",
        "            messages.append(ToolMessage(content=str(out), tool_call_id=tc[\"id\"]))\n",
        "        second = llm.invoke(full + messages)\n",
        "        messages.append(second)\n",
        "\n",
        "    return {\"messages\": messages}\n",
        "\n",
        "def construct_graph():\n",
        "    g = StateGraph(AgentState)\n",
        "    g.add_node(\"assistant\", call_model)\n",
        "    g.set_entry_point(\"assistant\")\n",
        "    return g.compile()\n",
        "\n",
        "graph = construct_graph()\n",
        "print(\"âœ… ê³µê¸‰ë§ ì—ì´ì „íŠ¸ ê·¸ë˜í”„ êµ¬ì„± ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
        "example = {\n",
        "    \"operation_id\": \"OP-12345\", \n",
        "    \"type\": \"inventory_management\", \n",
        "    \"priority\": \"high\", \n",
        "    \"location\": \"Warehouse A\"\n",
        "}\n",
        "convo = [HumanMessage(content=\"SKU-12345 ì¬ê³ ê°€ ì‹¬ê°í•˜ê²Œ ë¶€ì¡±í•©ë‹ˆë‹¤. í˜„ì¬ ì¬ê³ ëŠ” 50ê°œì´ì§€ë§Œ ë¯¸ì²˜ë¦¬ ì£¼ë¬¸ì´ 200ê°œì…ë‹ˆë‹¤. ì¬ì£¼ë¬¸ ì „ëµì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?\")]\n",
        "\n",
        "result = graph.invoke({\"operation\": example, \"messages\": convo})\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ­ ê³µê¸‰ë§ ì—ì´ì „íŠ¸ ì‘ë‹µ\")\n",
        "print(\"=\" * 60)\n",
        "for m in result[\"messages\"]:\n",
        "    print(f\"\\n{m.type}: {m.content}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
