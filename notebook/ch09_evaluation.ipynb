{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 09: ì—ì´ì „íŠ¸ í‰ê°€ (Evaluation)\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” AI ì—ì´ì „íŠ¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "\n",
        "## ì£¼ìš” ë‚´ìš©\n",
        "- Phrase Recall (êµ¬ë¬¸ ì¬í˜„ìœ¨)\n",
        "- Tool Metrics (ë„êµ¬ í˜¸ì¶œ ì •í™•ë„)\n",
        "- BERTScoreì™€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-repo/notebook/ch09_evaluation.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q bert-score sentence-transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. í‰ê°€ ë©”íŠ¸ë¦­ ì •ì˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Dict, List\n",
        "from bert_score import score as bert_score\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Sentence Transformer ëª¨ë¸ ë¡œë“œ\n",
        "st_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def phrase_recall(pred_reply: str, phrases: List[str]) -> float:\n",
        "    \"\"\"ì˜ˆì¸¡ ì‘ë‹µì—ì„œ ì˜ˆìƒ êµ¬ë¬¸ë“¤ì´ ì–¼ë§ˆë‚˜ í¬í•¨ë˜ì—ˆëŠ”ì§€ ì¸¡ì •\"\"\"\n",
        "    if not phrases:\n",
        "        return 1.0\n",
        "    found = sum(1 for p in phrases if p.lower() in pred_reply.lower())\n",
        "    return found / len(phrases)\n",
        "\n",
        "def tool_metrics(pred_tools: List[str], expected_calls: List[dict]) -> Dict[str, float]:\n",
        "    \"\"\"ë„êµ¬ í˜¸ì¶œì˜ ì •í™•ë„ ì¸¡ì •\"\"\"\n",
        "    expected_names = [c.get(\"tool\") for c in expected_calls]\n",
        "    if not expected_names:\n",
        "        return {\"tool_recall\": 1.0, \"tool_precision\": 1.0}\n",
        "    pred_set = set(pred_tools)\n",
        "    exp_set = set(expected_names)\n",
        "    tp = len(exp_set & pred_set)\n",
        "    recall = tp / len(exp_set)\n",
        "    precision = tp / len(pred_set) if pred_set else 0.0\n",
        "    return {\"tool_recall\": recall, \"tool_precision\": precision}\n",
        "\n",
        "def bert(pred, ref):\n",
        "    \"\"\"BERTScoreë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„\"\"\"\n",
        "    P, R, F = bert_score([pred], [ref], lang=\"en\", rescale_with_baseline=True)\n",
        "    return F.mean().item()\n",
        "\n",
        "def cosine(pred, ref):\n",
        "    \"\"\"ì„ë² ë”© ì½”ì‚¬ì¸ ìœ ì‚¬ë„\"\"\"\n",
        "    emb = st_model.encode([pred, ref], convert_to_tensor=True, normalize_embeddings=True)\n",
        "    return util.cos_sim(emb[0], emb[1]).item()\n",
        "\n",
        "print(\"âœ… í‰ê°€ ë©”íŠ¸ë¦­ ì •ì˜ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ë©”íŠ¸ë¦­ í…ŒìŠ¤íŠ¸\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í…ŒìŠ¤íŠ¸ ë°ì´í„°\n",
        "pred_response = \"ì£¼ë¬¸ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤. í™˜ë¶ˆì´ 3-5 ì˜ì—…ì¼ ë‚´ì— ì²˜ë¦¬ë©ë‹ˆë‹¤.\"\n",
        "expected_phrases = [\"ì·¨ì†Œ\", \"í™˜ë¶ˆ\", \"ì˜ì—…ì¼\"]\n",
        "\n",
        "pred_tools = [\"cancel_order\", \"send_notification\"]\n",
        "expected_tool_calls = [\n",
        "    {\"tool\": \"cancel_order\", \"params\": {\"order_id\": \"123\"}},\n",
        "    {\"tool\": \"issue_refund\", \"params\": {\"amount\": 50.0}}\n",
        "]\n",
        "\n",
        "reference = \"Your order has been cancelled. Refund will be processed within 3-5 business days.\"\n",
        "prediction = \"Order cancelled successfully. Expect refund in 3 to 5 working days.\"\n",
        "\n",
        "# ë©”íŠ¸ë¦­ ê³„ì‚°\n",
        "print(\"=\" * 50)\n",
        "print(\"ğŸ“Š í‰ê°€ ë©”íŠ¸ë¦­ ê²°ê³¼\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(f\"\\n1. Phrase Recall: {phrase_recall(pred_response, expected_phrases):.2f}\")\n",
        "print(f\"   (ì˜ˆìƒ êµ¬ë¬¸ {len(expected_phrases)}ê°œ ì¤‘ í¬í•¨ëœ ìˆ˜)\")\n",
        "\n",
        "tool_m = tool_metrics(pred_tools, expected_tool_calls)\n",
        "print(f\"\\n2. Tool Recall: {tool_m['tool_recall']:.2f}\")\n",
        "print(f\"   Tool Precision: {tool_m['tool_precision']:.2f}\")\n",
        "\n",
        "print(f\"\\n3. BERTScore: {bert(prediction, reference):.3f}\")\n",
        "print(f\"   (ì˜ë¯¸ì  ìœ ì‚¬ë„)\")\n",
        "\n",
        "print(f\"\\n4. Cosine Similarity: {cosine(prediction, reference):.3f}\")\n",
        "print(f\"   (ì„ë² ë”© ìœ ì‚¬ë„)\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
